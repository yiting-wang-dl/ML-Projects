{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNZNIBN0Lsvb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Credit Card Fraud Detecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalance Dataset. Anonymized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KzMVGQlLsve",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kaggle's Credit Card Fraud Dataset - RF\n",
    "\n",
    "In this HW you'll apply a Logistic regression classifier to the problem of detecting credit card fraud.\n",
    "\n",
    "The data is from: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "Note that there are 28 anonymized variables in the data set and the charge amount. The variable \"Class\" is 0 for no fraud and 1 if the charge was fraudulent. \n",
    "\n",
    "The data set is in your data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAgLLlsiLsve",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "1. Read in the data. How many observations do you have? What percentage of the data is fraudulent transactions? \n",
    "2. Create training (67% of the data) and test (33%) data sets. \n",
    "3. Fit a logistic regression classifier to the training data. \n",
    "4. Show the confusion matrix and accuracy for the training data. \n",
    "5. Show the confusion matrix and accuracy for the test data. Is there overfitting?\n",
    "6. Compute various other metrics you have learnt to assess the performance of your classifier and say if you are satisfied with its performance. \n",
    "7. Go ahead and try other techniques you might know of to improve the performance of your classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report,precision_recall_curve,roc_curve,recall_score, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data. How many observations do you have? What percentage of the data is fraudulent transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DSTMAA_data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001727485630620034"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 284807.00 observations in this dataset.\n",
      "The percentage of fraudulent transactions : 0.1727485630620034 %\n"
     ]
    }
   ],
   "source": [
    "print('There are %.2f observations in this dataset.'%(len(df)))\n",
    "print(\"The percentage of fraudulent transactions : {} %\" .format(np.sum(df.Class==1) *100 /len(df.Class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 284807 observations and 0.1727% of the data is fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "df1 = df.copy()\n",
    "var = df1.drop(['Class'], axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 features normally distributed.\n",
      "Top 5 features with highest P value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "V13      2.419974e-126\n",
       "Class     0.000000e+00\n",
       "V14       0.000000e+00\n",
       "V1        0.000000e+00\n",
       "V2        0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "norm_df = df1.apply(lambda x:stats.normaltest(x)[1])\n",
    "print(\"There are %d features normally distributed.\" % ((norm_df<0.05).sum()))\n",
    "print(\"Top 5 features with highest P value:\")\n",
    "norm_df.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(df1[var].values) \n",
    "std_df = pd.DataFrame(std_scaler.transform(df1[var].values), columns = var)\n",
    "std_df['Class'] = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create training (67% of the data) and test (33%) data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = std_df.drop(['Class'], axis=1)\n",
    "y = std_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit a logistic regression classifier to the training data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show the confusion matrix and accuracy for the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190463    121]\n",
      " [    27    209]]\n",
      "Accuracy = 0.9992243999580757\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels for the training set\n",
    "pred_train = model.predict(X_train)\n",
    "print(confusion_matrix(pred_train, y_train))\n",
    "print('Accuracy =', accuracy_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Show the confusion matrix and accuracy for the test data. Is there overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93810    65]\n",
      " [   15    97]]\n",
      "Accuracy = 0.9991488184536159\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels for the test set\n",
    "pred_test = model.predict(X_test)\n",
    "print(confusion_matrix(pred_test, y_test))\n",
    "print('Accuracy =', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the data is imbalanced and there is overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compute various other metrics you have learnt to assess the performance of your classifier and say if you are satisfied with its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Calculate AUC and graph ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9683328892441603\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "print('AUC =', roc_auc_score(y_test, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):  0.9683328892441603\n"
     ]
    }
   ],
   "source": [
    "y_score = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('FPR(1-specificity)')\n",
    "plt.ylabel('TPR (Recall)')\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot((0,1), ls='dashed',color='black')\n",
    "plt.show()\n",
    "print('Area under curve (AUC): ', auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93825\n",
      "           1       0.87      0.60      0.71       162\n",
      "\n",
      "    accuracy                           1.00     93987\n",
      "   macro avg       0.93      0.80      0.85     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is used for detecting credit card fraud, should focus on the recall value and the f1-score. Among the real positive values, we want to catch as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Change Regulation Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best C value\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "AUC_table = pd.DataFrame(columns = ['C_parameter','roc_auc_score'])\n",
    "AUC_table['C_parameter'] = C_param_range\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(penalty = 'l2', C = i,random_state = 0)\n",
    "    lr.fit(X_train,y_train)\n",
    "    \n",
    "    probs = lr.predict_proba(X_test)\n",
    "    \n",
    "    # Predict using model\n",
    "    #y_pred = lr.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    AUC_table.iloc[j,1] = roc_auc_score(y_test, probs[:,1])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.976685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.974072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.969533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.96819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.968173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter roc_auc_score\n",
       "0        0.001      0.976685\n",
       "1        0.010      0.974072\n",
       "2        0.100      0.969533\n",
       "3        1.000      0.968333\n",
       "4       10.000       0.96819\n",
       "5      100.000      0.968173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_table # 0.01 is the best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Apply the optimal c_parameter into the logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the optimal c_parameter into the logistics regression\n",
    "model2 = LogisticRegression(C = 0.01 )   # regulation for overfitting change C = 0.01\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93811    71]\n",
      " [   14    91]]\n",
      "Accuracy = 0.9990956196069669\n",
      "AUC = 0.9740717055984841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93825\n",
      "           1       0.87      0.56      0.68       162\n",
      "\n",
      "    accuracy                           1.00     93987\n",
      "   macro avg       0.93      0.78      0.84     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = model2.predict(X_test)\n",
    "probs2 = model2.predict_proba(X_test)\n",
    "print(confusion_matrix(predicted2, y_test))\n",
    "print('Accuracy =', accuracy_score(y_test, predicted2))\n",
    "print('AUC =', roc_auc_score(y_test, probs2[:, 1]))\n",
    "print(classification_report(y_test, predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall and f1-score did not change by much, we are not satisfied about this performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.3 Try using Lasso by changing penalty to L1 (default is L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logit_Lasso = LogisticRegression(penalty='l1',solver='liblinear',C=0.1)\n",
    "Logit_Lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93811    68]\n",
      " [   14    94]]\n",
      "Accuracy = 0.9991275389149563\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels for the test set\n",
    "pred_test_lasso = Logit_Lasso.predict(X_test)\n",
    "print(confusion_matrix(pred_test_lasso, y_test))\n",
    "print('Accuracy =', accuracy_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93825\n",
      "           1       0.87      0.58      0.70       162\n",
      "\n",
      "    accuracy                           1.00     93987\n",
      "   macro avg       0.93      0.79      0.85     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the recall and f1-score did not change much, we are not satisfied with this performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Go ahead and try other techniques you might know of to improve the performance of your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_2, y_train_2.ravel())\n",
    "\n",
    "clf = LogisticRegression(C = 0.01)\n",
    "model_res = clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9856540032223796\n",
      "Accuracy = 0.9752993223552544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     55466\n",
      "           1       0.94      0.06      0.12      1496\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.96      0.53      0.55     56962\n",
      "weighted avg       0.97      0.98      0.96     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_over = model_res.predict(X_test_2)\n",
    "probs_over = model_res.predict_proba(X_test_2)\n",
    "print('AUC =', roc_auc_score(y_test_2, probs_over[:, 1]))\n",
    "print('Accuracy =', accuracy_score(y_test_2, predicted_over))\n",
    "print(classification_report(predicted_over, y_test_2))\n",
    "# recall drops to 0.06 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest with oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = rf.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9440282634689666\n",
      "Accuracy = 0.9994908886626171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56876\n",
      "           1       0.78      0.92      0.84        86\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.96      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_rf = model_rf.predict(X_test_2)\n",
    "probs_rf = model_rf.predict_proba(X_test_2)\n",
    "print('AUC =', roc_auc_score(y_test_2, probs_rf[:, 1]))\n",
    "print('Accuracy =', accuracy_score(y_test_2, predicted_rf))\n",
    "print(classification_report(predicted_rf, y_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf2 = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9427695045609603\n",
      "Accuracy = 0.9994999308414994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93852\n",
      "           1       0.77      0.93      0.84       135\n",
      "\n",
      "    accuracy                           1.00     93987\n",
      "   macro avg       0.89      0.96      0.92     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_rf2 = model_rf2.predict(X_test)\n",
    "probs_rf2 = model_rf2.predict_proba(X_test)\n",
    "print('AUC =', roc_auc_score(y_test, probs_rf2[:, 1]))\n",
    "print('Accuracy =', accuracy_score(y_test, predicted_rf2))\n",
    "print(classification_report(predicted_rf2, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1-CC_Fraud_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
